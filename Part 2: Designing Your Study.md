With a clear question, you can now design the study. For estimating "how common" something is, a cross-sectional study is often the best choice. It’s like taking a snapshot—it captures what's happening at a single point in time. For a prevalence study manual-checklist HERE.

2.1 Define Your Population and Sampling Strategy
Your study's credibility rests on who you study and how you select them. For further elaboration on samplings here, and online survey here.

In many clinical research settings, a pre-existing, comprehensive list of the entire target population, a classic sampling frame, is rarely available. The challenge is that the population is often dynamic (e.g., patients who will change in their disease status, clinic attendance, place of residence, etc). Therefore, the concept of a sampling frame must be adapted.

For clinical studies, the sampling frame becomes the operational definition of the source population from which you will recruit participants. It is the specific group of accessible individuals who meet your eligibility criteria over a defined period. Defining this frame precisely is critical, as inaccuracies or omissions of a certain pattern during recruitment could miss an opportunity of efficiency in sampling methods, or be a major source of selection bias, and can limit the generalizability of your findings (see Box Information 2 for more on generalizability).

Examples of Operational Sampling Frames:
  •	For a cross-sectional study: "All adults aged 30 or older living with hypertension attending the Klinik Kesihatan Serdang outpatient clinic for any reason between July to August 2025, who agree to participate."
  •	For a retrospective study: "All patients with a diagnosis of Type 2 Diabetes (ICD-10 code E11.x) in the electronic medical records of the Klinik Kesihatan Serdang database as of today, July 15, 2025."
  •	For a prospective study: "All patients aged 18-65 who present to the Serdang Hospital Emergency Department with a first-time diagnosis of acute coronary syndrome between January 1, 2026, and December 31, 2026."

1. Define the Target Population:
Be precise about your inclusion criteria (who's in) and exclusion criteria (who's out). This defines who your results can be generalized to.
  * Example: "All adults aged 30 or older with diagnosed hypertension attending Klinik Kesihatan Serdang between year 2020 and 2025, inclusive".

3. Choose a Sampling Strategy:
Your goal is a representative sample—one that mirrors the characteristics of your target population.

●	Probability Sampling (ideal but often impractical): Every individual in the population has a known, non-zero chance of being selected. This minimizes selection bias. Examples include:
  * Systematic Sampling: A practical approach when patients present over time. After a random starting point, you approach every nth patient who meets the eligibility criteria (e.g., screening every 5th patient registering at the clinic). This approximates random selection without needing a complete list in advance.
  * Simple Random Sampling: Feasible only when you have a complete list (e.g., from an electronic medical record query). Every individual on the list is assigned a number, and a random number generator is used to select participants.

●	Non-Probability Sampling (commonly used with caution): While several non-probability methods exist, consecutive sampling stands out as a practical and often valid approach in clinical settings where the patient flow is dynamic. This method involves recruiting every eligible patient who presents over a specified timeframe. If the dynamic sampling frame is free of systematic patterns (e.g., sicker patients don't all arrive on specific days), consecutive sampling is efficient and can yield a sample with less selection bias than other convenience methods. Other approaches like general convenience sampling (recruiting those easiest to access) or purposive sampling (selecting specific individuals) are highly prone to selection bias and limit generalizability. Their use must be clearly justified.
  * Consecutive Sampling: A strong form of non-probability sampling. You recruit every eligible patient who meets the inclusion criteria from your source population over a specified time. This approach reduces the researcher's ability to consciously or subconsciously select patients, thus minimizing selection bias compared to other convenience methods.
  * Convenience Sampling: Recruiting participants based on their easy availability (e.g., patients attending a clinic only on the days the researcher is present). This method is highly susceptible to selection bias as the sample may not be representative of the overall patient population.
  * Purposive Sampling: Intentionally selecting participants with specific characteristics or experiences relevant to the research question (e.g., seeking out patients who have successfully adhered to a complex treatment regimen for over five years). This is useful for qualitative or highly targeted studies but is not intended to be generalizable.

•	Essential Final Check: Assess Representativeness
No matter the sampling method chosen, a crucial final step is to check the representativeness of your study sample. You must compare the key demographic and clinical characteristics of your participants against the known or published parameters of the target population. This assessment is vital for identifying potential biases and understanding the true extent to which your findings can be generalized.

2.2 Determine Your Sample Size 
Guessing isn't enough—you must calculate your sample size before starting. An adequate sample size ensures your findings are precise, reliable, and not due to chance.

You often need to calculate the sample size for two different objectives: prevalence estimation and association analysis (regression), and then use the larger of the two calculations. Below are brief explanations, and for a further elaboration here, use a simple online calculator here on Google’s AI studio (DO NOT ‘mess’ with the codes or its features).

A. Sample Size for Prevalence Estimation:
This ensures your "snapshot" is sharp and not blurry.
  
  ●	Formula:  
  ●	You'll need:
  * Z: Z-score for your desired confidence level (typically 1.96 for 95% confidence).
  * P: Expected prevalence of the condition from past studies. If unknown, use 50% (0.5) as it gives the largest sample size.
  * d: Desired margin of error (e.g., 0.05 for ±5%).

Explanatory Note for Subgroups: If you plan to analyze subgroups (e.g., by age or gender), you must calculate the sample size based on the subgroup with the lowest expected prevalence to ensure precision for that group. This will significantly increase your total required sample size.

B. Sample Size for Association (Multivariable Regression):
This ensures your study has enough power to find true relationships between variables.

●	For Logistic Regression (Binary Outcome, e.g., Yes/No):
  * Rule of Thumb: Aim for at least 10 Events Per Parameter (EPP). An "event" is the outcome of interest (e.g., having the disease). A "parameter" refers to each variable or category within a variable in your model.
  * Calculation:
1.	Required Events = 10 × (Number of predictor parameters).
2.	Total Sample Size = Required Events / Expected Event Rate (Prevalence).

Examples of sample size estimation description HERE.

2.3 Select and Validate Your Measurement Tools
What you use to measure is as important as what you measure. Your tool, typically a questionnaire, must be both valid and reliable. For a further elaboration on quality questionnaires here.

●	Validity (Accuracy): Does it measure what it's supposed to?
  *	Content Validity: Do experts agree the questions cover the topic thoroughly?
  *	Face Validity: Does it make sense to the participants? A pilot test is essential for this.
  * Assessment is qualitative, typically involving a panel of 5-10 experts and a similar number of representative patients.

●	Reliability (Consistency): Does it produce the same results under the same conditions?
  * Internal Consistency: Measured with Cronbach's alpha for scales (a value ≥ 0.70 is acceptable). At least 100 subjects are needed to ensure a stable estimate of Cronbach's alpha.
  * Test-Retest Reliability (or Intra-rater Reliability): The extent to which scores for stable patients remain the same on repeated measurements over time. It assesses the instrument's stability. A minimum of 50 subjects is recommended for this analysis.
  * Inter-Rater Reliability: The extent to which scores from two or more different raters match for the same subjects. This is crucial for observer-reported outcomes. A minimum of 50 subjects is recommended.

●	Construct Validity: 
  * Structural Validity: Assesses the internal structure of the instrument and whether it reflects the intended dimensionality. It is most often evaluated using Factor Analysis. A subject-to-item ratio of at least 10:1 (e.g., 100 subjects for a 10-item scale) is a common rule of thumb, with a minimum sample size of 100 being a widely accepted guideline for Exploratory Factor Analysis (EFA).
  * Hypotheses Testing: Involves testing predetermined hypotheses about expected correlations between the instrument's scores and other measures. A minimum of 50 subjects is recommended.

●	Responsiveness: This is evaluated by testing specific hypotheses about expected changes in scores over time in response to an intervention or known change in health status. A minimum of 50 subjects is recommended.


●	Pre-testing and Pilot Study:
o	Pre-testing: Administer the draft questionnaire to a small group (5-10 individuals) from the target population to check for clarity, flow, and length. Use "think-aloud" protocols.

Best Practice: Always try to use a previously validated questionnaire. If you are using it in a new language or population, it must be professionally translated, back-translated, and culturally adapted.

●	For Linear Regression (Continuous Outcome, e.g., a Score):
  *	Rule of Thumb: Aim for at least 20 subjects per independent variable.
  * Calculation: Total Sample Size = 20 × (Number of independent variables).

C. Finalizing Your Sample Size:
1.	Compare: Choose the largest sample size calculated for your various objectives.
2.	Adjust: Increase this number to account for potential dropouts or non-responses (e.g., by 20%).
○	Final Size = Required Sample Size / (1 – Anticipated Non-response Rate).
